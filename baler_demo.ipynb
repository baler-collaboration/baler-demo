{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "<!--Run this before presenting!-->\n",
    "<style>\n",
    "table {float:left}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Baler - Machine Learning Based Data Compression Tool\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The Probelm\n",
    "* “Data deluge”: when the sheer volume of new data being generated is overwhelming the storage and processing capacities\n",
    "* An increasingly common problem in both academia and industry.\n",
    "<div>\n",
    "<img src=\"figures/data_deluge.png\" width=\"700\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Solution\n",
    "* One approach: Lossy compression (Like mp3 for music)\n",
    "* One catch: Lossy compression needs to be tailored\n",
    "* Solution: Lossy Machine Learning based compression\n",
    "<div>\n",
    "<img src=\"figures/AE.png\" width=\"900\"/>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Our Tool: “Baler”\n",
    "* We have created a tool called “Baler” to help investigate the viability of this compression\n",
    "* Multidisciplinary tool, easy to install and run as a python pachage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eX0s7ygpFerQ",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "!pip install baler-compressor\n",
    "    \n",
    "import baler_compressor.config as config_module\n",
    "import baler_compressor.trainer as trainer_module\n",
    "import baler_compressor.compressor as compressor_module\n",
    "import baler_compressor.decompressor as decompressor_module\n",
    "\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* Distributed and developed as an open source project\n",
    "    - https://github.com/baler-collaboration/baler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## X-ray Tomogapy Input Data (exafel_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NP7RynYGKXDh",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import helper\n",
    "\n",
    "data = np.load(\"input/exafel_1.npz\")[\"data\"]\n",
    "data_decompressed = data*0\n",
    "\n",
    "helper.plot2D(data[0], data_decompressed[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Baler Workflow\n",
    "<div>\n",
    "<img src=\"figures/workflow.png\" width=\"800\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Define Training Parameters (config file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1TzrUj-SFwe3",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "config = config_module.Config\n",
    "config.compression_ratio = 1000\n",
    "config.epochs = 1\n",
    "config.early_stopping = False\n",
    "config.early_stopping_patience = 100\n",
    "config.min_delta = 0\n",
    "config.lr_scheduler = True\n",
    "config.lr_scheduler_patience = 50\n",
    "config.model_name = \"CFD_dense_AE\"\n",
    "config.model_type = \"dense\"\n",
    "config.custom_norm = True\n",
    "config.l1 = True\n",
    "config.reg_param = 0.001\n",
    "config.RHO = 0.05\n",
    "config.lr = 0.001\n",
    "config.batch_size = 75\n",
    "config.test_size = 0.2\n",
    "config.data_dimension = 2\n",
    "config.apply_normalization = False\n",
    "config.deterministic_algorithm = False\n",
    "config.compress_to_latent_space = False\n",
    "config.convert_to_blocks = [1, 150, 150]\n",
    "config.verbose = False\n",
    "\n",
    "\n",
    "input_data_path = \"input/exafel_1.npz\"\n",
    "output_path = \"output/\"\n",
    "model_path = output_path + \"compressed_output/model.pt\"\n",
    "normalization_path = output_path + \"compressed_output/normalization_features.npy\"\n",
    "compressed_path = output_path + \"compressed_output/compressed.npz\"\n",
    "decompressed_path = output_path + \"decompressed_output/decompressed.npz\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Training\n",
    "| Parameters | Returns |\n",
    "| :---: | :---: |\n",
    "| Data path | Trained pyTorch model |\n",
    "|Config|Normalization features|\n",
    "||Loss data|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-jgQSjD1F87N",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "model, normalization, loss_data = trainer_module.run(input_data_path, config)\n",
    "\n",
    "torch.save(model.state_dict(), model_path)\n",
    "np.save(normalization_path,normalization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Using pre-trained model\n",
    "* 1000 Epochs\n",
    "* 2 minutes of training on laptop CPU\n",
    "* 36.3 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Use pre trained model:\n",
    "model_path = output_path + \"compressed_output/model_preBaked.pt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Compression\n",
    "| Parameters | Returns |\n",
    "| :---: | :---: |\n",
    "|Data path|Compressed data|\n",
    "|Model path|Column names|\n",
    "|Normalization features|Original shape|\n",
    "|Config||"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eNgJNvKnF_gl",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "compressed, names, original_shape = compressor_module.run(input_data_path, model_path,normalization, config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Saving compressed data to disk\n",
    "* We can save the returns to disk as the decompressed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Latent space:\\n\",compressed[0])\n",
    "np.savez_compressed(\n",
    "    compressed_path,\n",
    "    data=compressed,\n",
    "    names=names,\n",
    "    normalization_features=normalization,\n",
    "    original_shape=original_shape,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Running Decompression\n",
    "| Parameters | Returns |\n",
    "| :---: | :---: |\n",
    "|Model path|Decompressed data|\n",
    "|Compressed path|Column names|\n",
    "|Config|Original shape|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k3bh5qh9GWhm",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "decompressed, names, original_shape = decompressor_module.run(model_path, compressed_path, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Saving decompressed data  to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "np.savez(decompressed_path, data=decompressed, names=names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evaluating performance\n",
    "* Use extrenal plotting to look at performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rKqlONa5J8D3",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "data = np.load(\"input/exafel_1.npz\")[\"data\"]\n",
    "data_decompressed = np.load(\"output/decompressed_output/decompressed.npz\")[\"data\"].reshape(data.shape[0], data.shape[1], data.shape[2])\n",
    "helper.plot2D(data[10], data_decompressed[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Offline vs Online compression\n",
    "* Offline compression is always done on data which is fully aquired\n",
    "    - A single model is then derived for that one dataset\n",
    "    - Auxilliary files decreases performance\n",
    "* Online compression can be done on data in real time\n",
    "    - Uses a model derived on similar, previously aquired datasets\n",
    "    - Auxilliary files do not count towards final compressed file size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Demonstrating online compression\n",
    "* New, but similar, dataset \"exafel_2\"\n",
    "* Same model as was derived from \"exafel_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SmvckbKLMkQv",
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Run compression\n",
    "compressed, names, original_shape = compressor_module.run(\n",
    "    \"input/exafel_2.npz\",\n",
    "    model_path,\n",
    "    normalization,\n",
    "    config,\n",
    ")\n",
    "# Save compressed file\n",
    "np.savez_compressed(\n",
    "    output_path + \"compressed_output/compressed2.npz\",\n",
    "    data=compressed,\n",
    "    names=names,\n",
    "    normalization_features=normalization,\n",
    "    original_shape=original_shape,\n",
    ")\n",
    "# Run decompression\n",
    "decompressed, names, original_shape = decompressor_module.run(\n",
    "    model_path,\n",
    "    output_path + \"compressed_output/compressed2.npz\",\n",
    "    config,\n",
    ")\n",
    "# Save decompressed file\n",
    "np.savez(\n",
    "    output_path + \"decompressed_output/decompressed2.npz\",\n",
    "    data=decompressed,\n",
    "    names=names,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evaluation of Online compression\n",
    "* We have compressed a file down to 0.001% its original size\n",
    "<div>\n",
    "<img src=\"figures/size.png\" width=\"400\"/>\n",
    "</div>\n",
    "* And this is the reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q7HAxWnwSgFD",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import helper\n",
    "data = np.load(\"input/exafel_2.npz\")[\"data\"]\n",
    "data_decompressed = np.load(\"output/decompressed_output/decompressed2.npz\")[\"data\"].reshape(data.shape[0], data.shape[1], data.shape[2])\n",
    "helper.plot2D(data[10], data_decompressed[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Outlook\n",
    "* The interest for machine learning based offline compresion is limited\n",
    "* The interest for online compression is unlimited?\n",
    "    - Telecom\n",
    "    - Autonomous vehicles\n",
    "    - Detector readout\n",
    "    - Anything with bandwidth constraints\n",
    "    0.5% Original Size             |  0.001% Original Size\n",
    ":-------------------------:|:-------------------------:\n",
    "![](figures/CFD.gif)  |  ![](figures/xray.gif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "<p style=\"text-align: center;\"> <b>65% Original Size</b>\n",
    "<div>\n",
    "<img src=\"figures/HEP.png\" width=\"800\"/>\n",
    "</div>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Slideshow",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
